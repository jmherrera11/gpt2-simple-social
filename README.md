#  GPT-2 (Simple) Social Media Text Generation

Original notebook by [Max Woolf](http://minimaxir.com)
Updated for social media scraping by [Shaunak G](https://github.com/shaunakg)  

Retrain an advanced text generating neural network on any text dataset for free on a GPU using Collaboratory using `gpt-2-simple`. Scrape text from reddit, twitter or tumblr using the associated libraries and train the neural network with it.

For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read the original creator's [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook.

To get started:

1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)
2. Make sure you're running the notebook in Google Chrome.
3. Run the cells below.  
  
*Note: some cells have been commented out for continuity when running (Runtime -> Restart and Run All). You can mix and match the cells by deleting or commenting them out yourself if you want to change functionality.*
